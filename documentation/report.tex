\documentclass{article}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{caption}
\graphicspath{ {./image/} }
\usepackage{natbib}
\usepackage{doi}
\usepackage{arxiv}
\usepackage{makecell}
\usepackage{tcolorbox}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usepackage{setspace}
\doublespacing

\usepackage{makeidx}
\usepackage{hyperref}
\makeindex

\tcbset{colframe=gray}

% Make a box for interesting side information.
\newcommand{\infobox}[2]{
  \begin{tcolorbox}[width=\textwidth,colback={white},title={\strut\textbf{#1}},colbacktitle=blue!15,coltitle=black,boxrule=0.2pt,parbox=false]
    #2
  \end{tcolorbox}
}

% Format terms and optionally add to our index.
\newcommand{\noterm}[1]{\textit{#1}}
\newcommand{\term}[1]{\noterm{#1}\index{#1}}

\newcommand{\icode}[1]{\texttt{#1}}

% Archaic new paragraph, not used in the text itself.
\newcommand{\newp}{\newline\indent}

% Line formatted as an important callout with a text label.
\newcommand{\imp}[2]{
  \begin{quote}
    \textit{#2}\newp \textsc{#1}
  \end{quote}
}

% Marcus conversation formatting.
\newcommand{\user}[1]{\texttt{#1}}
\newcommand{\marcus}[1]{\textit{#1}}

\newcommand{\isubsubsubsection}[1]{\subsubsubsection{\textbf{#1}}}

\newcommand{\screenshot}[2]{
  \begin{figure}[h]
    \includegraphics[width=\textwidth]{#1}
    \caption*{#2}
  \end{figure}
}

\begin{document}

\title{Cloud Enlightenment}

\author{Written by Joseph Rubin '22 (jmrubin) for the BSE COS program.}

\date{}
\maketitle

\thispagestyle{empty}

% The Abstract and Introduction work together to motivate the thesis and launch the reader forward.

\begin{abstract}
  University students studying computer science are often asked to complete solo coding assigments with lifespans of just a couple weeks or build projects that last one or two semesters.
  For those of us going into industry, the real world has rules that challenge our experiences:
  Software can't be thrown out after a fortnight because it might have to work for years, and projects with any amount of complexity are often completed by teams and not individuals.
  How are production-grade applications built to persist across many person-months of development and years of use?
  This thesis provides the answer.
  This is a report in software design, and more specifically, in architecting cloud applications.
  First we develop key ideas by examining the current cloud landscape and then we practice our method by building and examining a number of applications.
  Of particular note is Jongleur, a web application for musicians that ingests and catalogues audio recordings, but we approach this capstone project by working our way through an assortment of interesting cloud apps.
\end{abstract}

\newpage

\section{Introduction}

In 2017 I met the brother-in-law of Joel Spolsky, Co-Founder and Chairman of Stack Overflow.~\cite{stack-overflow}
Spolsky's blog \textit{Joel on Software} contains a lot of gems on software engineering and business.
Here's one:

\begin{quote}
  The idea that new code is better than old is patently absurd.
  Old code has been \textit{used}.
  It has been \textit{tested}.
  \textit{Lots} of bugs have been found, and theyâ€™ve been \textit{fixed}.

  \ldots

  When you throw away code and start from scratch, you are throwing away all that knowledge.
  All those collected bug fixes.
  Years of programming work.

  You are throwing away your market leadership.
  You are giving a gift of two or three years to your competitors, and believe me, that is a \textit{long} time in software years.~\cite{joel-old-code}
\end{quote}

Seems pretty bad to rewrite code!
But of course the only way to ensure your code doesn't \textit{need} to be thrown away is to write it well the first time.
And it's not only about taking care to make each line just right; it's important to consider the macrolevel too.
A well written algorithm will be torn out and replaced if that algorithm isn't important to the system.
If a part of your program reads from a database, writes files to a storage bucket, or spins up servers, you'll have to rip out all the code that interfaces with or runs on that infrastructure if you realize later down the line that your approach was misguided or you've chosen the wrong architecture.

It's no wonder that the software development lifecycle consists heavily of planning, analysing, and designing.

\begin{figure}[h]
  \centering
  \tikzstyle{notcoding} = [rectangle, rounded corners, minimum width=2.427cm, minimum height=1.5cm, text centered, draw=black, text=white, fill=gray]
  \tikzstyle{coding} = [rectangle, rounded corners, minimum width=2.427cm, minimum height=1.5cm, text centered, draw=black]
  \tikzstyle{arrow} = [thick,->,>=stealth]
  \begin{tikzpicture}[node distance=4cm]
    \node (one) [notcoding] {Plan};
    \node (two) [notcoding, right of=one] {Analysis};
    \node (three) [notcoding, right of=two] {Design};
    \node (four) [coding, below of=three] {Implementation};
    \node (five) [coding, left of=four] {Verification};
    \node (six) [coding, left of=five] {Deployment};

    \draw [arrow] (one) -- (two);
    \draw [arrow] (two) -- (three);
    \draw [arrow] (three) -- (four);
    \draw [arrow] (four) -- (five);
    \draw [arrow] (five) -- (six);
    \draw [arrow] (six) -- (one);
  \end{tikzpicture}
  \label{fig:sdl}
\end{figure}

Thus is seems prudent to focus on these phases, the output of which is your \term{architecture}, a high-level description of all the components of your software, such as modules of code and cloud resources, and the mechanisms by which they interact with each other.

This thesis contains the knowledge I've gained as a result of researching, designing, and writing cloud software.
In section XXX, there is XXX, YYY YYY TODO

\section{Things we will discuss}

TODO: merge this section up with the end of the Introduction.

Toy example: Marcus

Example: Traxler

Example: Blodkorv

Example: Agora

Main example: Jongleur

\subsection{What this is not}

Before going further let's discuss what \textit{won't} be covered.

Not about research into reducing cold starts.

Not about SNS and SQS.

Not specifically about FaaS.

But also not about other aaS models.

It's also not about the benefits of Serverless from an operational point of view.
E.g. we aren't going to talk about reduced need for monitoring.
In fact you probably still need to monitor the system as a whole even if not the lambda.
Or maybe the lambda too... what if some VPC changes and the lambda no longer works?

This is also not a report about testing or test-driven-development.

\section{Applications that scale}

All it takes to build custom software is computer access and some programming knowledge.
But to build \textit{good} software, now that takes the right tools!
Here are a few questions that may come up when you are making a web app:

\begin{enumerate}
  \item What version control system should I use?
  \item How will I host this app and make it available to others?
  \item What CSS framework will best suit this project?
\end{enumerate}

Rather than taking a side on these issues (as there is more than one decent option for each item above), we'll discuss how to utilize the tools you've chosen.
For example:

\begin{enumerate}
  \item What should I put in my version control?
  \item Once my app is hosted, how do I neatly deploy new versions?
  \item How do I run my CSS preprocessor during the build step?
\end{enumerate}
Writing applications that scale takes discipline and enough experience to make the right decisions.
And by \term{scale}, I don't just mean \noterm{supports a large (or unpredictable) volume of users}.
I mean that the application can easily grow as the users' needs change.
It's the feature set which scales.
It's the size of the development team which scales.
It's the number of reported bugs which scales.

In this report, we'll examine four key properties of successful software development (and a number of smaller ones) that play an integral role in the development of apps that scale:

\begin{enumerate}
  \item Repetition and consistency
  \item Statelessness
  \item Infrastructure as code
  \item Serverlessness
\end{enumerate}
Later, to demonstrate each one, we'll look at \# example applications that display these finer details of software development.

\section{Do your best, then do it again!}

Projects that succeed must succeed over and over again.
The \textit{worst} kind of software to work on is one where things sometimes work and sometimes fail.
We usually write test casess to ensure that our code works, but this isn't enough by itself.
Consider that Google has a team dedicated to understanding and monitoring flaky tests~\cite{google-flaky-blog} (tests which behave inconsistently even when the code doesn't change) and they've written extensively about their research into detecting the causes of flakiness.~\cite{google-deflake}
Almost unbelievably, in 2018 Google spent "between 2 and 16\% of [their] compute resources re-running flaky tests."~\cite{google-testing}

Why do tests flake?
Most often it's because they rely on some external agent to run.
If the test needs to make a request over the public internet, for example, any number of network-dependant factors could vary between runs.
And if the data that comes back from the request isn't generated from scratch at the beginning of the test, you can't be sure that the test will execute the same way every time.
Of course, tests which rely on pseudorandom number generation will also be prone to flakiness unless you fix the seed at the beginning of testing.

One way to make sure that code always works the same way every time is the so-called \term{Hermetic Server}.~\cite{google-hermetic-servers}
Picture a sealed application environment running your binary without any uncontrolled access to the outside world.
The addresses of any network connections that the system needs are hardwired into the server's environment when it's deployed, and any required data is mocked locally.\footnote{
  We'll stray a little from the definition given in the reference here and allow hardwired addresses to databases too, as long as the database is populated deterministically at deploy time or as a result of automated tests that run the same way every time.
}
Once you have a Hermetic Server, it should be easy to run automated tests against it that behave \term{consistently}.
But how can we create a Hermetic Server whenever we want to run our tests?

Since deploying our application generally involves (1) building our program from the source repository and (2) running our program on its intended infrastructure, the best way to produce a predictable system is to have everything that could possibly affect the deployment residing in the repository.
Of course, all of your source code will be there, but all of the packages and libraries you depend on should be too (or at the very least a detailed list of each package and exactly which version you need so that they can be retrieved when the program is being built).
Additionally, for cloud apps, every resource that the system is comprised of should be detailed in the repository.
This is the meaning of \term{Infrastructure as Code}, discussed in \ref{sec:IAC}.
Furthermore, the test files themselves should be kept in version control alongside the source code.

What do we gain from hermeticity?
By creating an environment that's consistent and airtight, a commit in your version control software becomes \textit{a complete and accurate account of the behavior of your software project at a single point in time}.
If you write code later than introduces a bug, you will always be able to revert to a previous commit and expect the exact same (working) behavior that you had before, no exceptions.

By the way, if merged commits automatically get deployed then commits are now not just a representation of your application's behavior but also a representation of exactly what your users are seeing. \ref{sec:CD}
That is pretty sweet because it means that you will be confident that any issue in production can be immediately remedied by rolling back to a previous version that your users were happy with.

This only works if deploying an old version of your app doesn't cause loss of valuable state that's been built up as the program has been running.
So it's time to\ldots.

\section{Remove state!}

State is bad.
We all know that!
Why is state bad?

State refers to any part of a program that depends on what's already happened.
A functional programmer might argue that \textit{global state} is bad because it makes it hard to reason about the behavior of functions.
For example, if a method relies on the value of a global variable, you might invoke the method twice with the same explicit input and get two different results if the global was modified in between.

But we aren't functional programmers; we build real apps that do useful things!
Still, state is bad because it hinders \term{repeatablility}.
This is because state is the result of \term{progress} and \term{progress} can't always be replayed later, especially if our state was caused by user interaction.
But not \textit{all} state is bad, just as not all state affects repeatability in a harmful way.

For example, a website might track how many visitors it's gotten each day and display this number on the homepage.
Since this value presents a meaningful (and potentially useful) datum, it's a valid use of state.

But if the website keeps track of this number on the file system of the server it's running on, it would be in violation of the Rule of State:
\imp{Rule of State}{Don't put global application state on the same infrastructure as your code.}

Just think about it this way.
If you wanted to run your application on multiple servers you wouldn't be able to, because each server would be tracking a different value.
Now users who connect to different servers will see a different number on the homepage.
Instead, the website could read from and write to an external, atomic data store to manage this kind of usage data.
A database is definitely a form of global application state, but it's acceptable in this instance because it is separated from the business logic and thus can be scaled independantly of the application runtime.
This way, the Rule of State is not violated.

\infobox{Horizonal scaling}{
  Why would you want to run an application on multiple servers at once?
  If this website was receiving too much traffic for the original server to handle, you might try to increase the CPU or memory of the machine.
  This is called \term{vertical scaling}, and it is generally easy to do using a cloud provider.

  However, at a certain point it will become prohibitively costly or impossible to grow the single instance any further.
  Instead, consider \term{horizonal scaling}, the practice of deploying your app to multiple servers at once.

  The benefits are huge:
  You no longer have a single point of failure, so if a machine goes down, traffic can be transparantly directed to the others.
  Your app can dynamically scale by automatically launching or terminating instances in response to load.
}

To summarize, the particular server that a user's session lives on should be functionally transparent to the user.
(In section \ref{sec:serverless}, we take this to the extreme and discuss how to make the server transparant to the developer as well.)

And in general, any local state should be ephemeral.
It's hard to back up state that's kept on the same machine as your application code, but that's okay if the data isn't all that important.

However, there \textit{are} times (when the user can't percieve a functional difference) where local state is acceptable.
For example, if each server running your code builds up a local cache of data in its filesystem to speed up transactions, the user will only ever be positively impacted by this use of state.
It's okay for each server to have a different cache; the cache does not affect the behavior of the code, only its performance.
And if one of the servers gets terminated, no important information was lost.

\section{Infrastructure-as-Code}
\label{IAC}

Megillas have been written about this topic~\cite{iac-book}, so what makes this section worth reading?
Well this report is being written in 2022 while the above book came out at the end of 2020.
That doesn't seem like a big difference, but things move \textit{fast} in cloud computing.
AWS CDK, the IaC tool we'll discuss in the most depth, only became generally available in 2019~\cite{cdk-1} and CDK v2 only hit general availability at the end of 2021.~\cite{cdk-2}

Also, you'll find that the opinions expressed here differ from those that other authors express. Let's get into it.

Infrastructure as code (IaC) is primarily a way to integrate the resources used by your app into your source code (and thus your version control).
This provides many benefits over manually privisioning your infrastructure in a GUI or command-line.
Consistent with the pattern of repeatability, using IaC means that you will produce the same infrastructure every time, and having your infrastructure in your repository means you can apply version control to it like the rest of your code.

There are a few different ways that we can encode our infrastructure into our source repository.
The most basic way is to use a representation language like JSON or YAML.
For example, the AWS CloudFormation service can read your JSON or YAML template and coax an infrastructure stack into existence that matches your description.
This is a somewhat primitive form of IaC, much like writing your infrastructure in assembly language, and there are better options.

The second form that IaC mainly takes is the \term{Domain Specific Language} (DSL).
A DSL is a language built for a particular purpose, and there are a few designed specifically to encode infrastructure.
For example, the Terraform~\cite{terraform} project's DSL is called HashiCorp Configuration Language (HCL) and it looks like this:

\begin{verbatim}
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 3.27"
    }
  }

  required_version = ">= 0.14.9"
}

provider "aws" {
  profile = "default"
  region  = "us-west-2"
}

resource "aws_instance" "app_server" {
  ami           = "ami-830c94e3"
  instance_type = "t2.micro"

  tags = {
    Name = "ExampleAppServerInstance"
  }
}
\end{verbatim}~\cite{terraform-example}

Each resource is \textit{declared} along with its configuration arguments and Terraform figures out how to deploy your infrastructure when you tell it to.
Also using a DSL means you have to learn a new language, the resultant code is much clearer thatn the equivalent JSON or YAML.

The last option is an IaC framework for an imperative language.
The framework provides a library of classes and functions for describing infrastructure in a familiar language like TypeScript, Python, or Java, and tools to turn your code into a representation template that is read by a classical IaC system like CloudFormation.
The AWS Cloud Development Kit (CDK) is a particularly popular framework and is available for many imperative languages.
It looks like this:

\begin{verbatim}
const vpc = new ec2.Vpc(this, 'Vpc');

// Declare a new EC2 Instance in our virtual private cloud.
new ec2.Instance(this, 'Instance', {
  vpc: vpc,
  instanceType: ec2.InstanceType.of(ec2.InstanceClass.R5, ec2.InstanceSize.LARGE),
  machineImage: new ec2.AmazonLinuxImage(),
});
\end{verbatim}

As you can see, resources are created and configured using normal JavaScript objects.

Some think that declarative DSLs like HCL are better suited for IaC than imperative languages.
After all, the DSL is specifically designed for this use, and its limitations mean you will make fewer mistakes.

This is misguided.
Using a general-purpose language has many advantages:

\begin{enumerate}
  \item You can use the same tools and programming practices you use for the rest of your code, including testing frameworks and IDE autocompletion, not to mention programming paradigms like modules and classes.
  \item Control-flow statements are useful when templating infrastructure because they allow you to specify complex behavior with fewer lines of code.
  \item You can write your IaC in the same language as your application's source code; doing so allows you to share types, constants, and utilities easily, eliminating lots of bugs.
  \item The software engineer takes back control of their own infrastrcture from the sysadmins by writing in a language they are already familiar with.
    After all, the developer is the expert in their application; not the system administrator.
\end{enumerate}

Well-written IaC frameworks for imperative languages do not miss out on the advantages of DSLs because \textit{when the type system is good enough, the construct library and your text editor's autocomplete becomes your DSL.}

This is very similar to how an Object-relational Mapper (ORM) hides the details of the underlying SQL code from the developer so she can communicate with the database using native objects to her programming language of choice.
The fact that sqlalchemy, a popular Python ORM, gets over 45 million downloads a month shows that ORMs are extremely useful and they aren't going anywhere.~\cite{sqlalchemy-stats}
Consider IaC frameworks like CDK to be in the same boat.

And how much time do we save by writing our infrastructure using CDK vs CloudFormation?
Turns out, quite a lot.
We'll later consider a project called Marcus whose CDK code is only 80 lines long but which synthesizes to a CloudFormation template that's 450 lines long.
It's a good thing when you only have to maintain less than 20\% of the code!

\subsection{Save the environment}

A major part of consistency is ensuring that your test/qa/stage environments behave exactly the same as your production environment.
You would be extremely displeased if you spent hours writing an extensive suite of end-to-end tests for your application and got all of them to pass during QA if the actual production deployment had issues.

\term{Infrastructure as code} really helps in this regard because a stack will deploy the same way every time.
You can change the line of code that says what account to provision the resources in and just like that you've created an isolated environment with a full copy of all of your infrastructure running your code.

My recommendation is to have a single deploy script that takes the name of the environment you want to deploy to (\texttt{stage}, \texttt{prod}, \texttt{test}, \texttt{qa}, whatever) and starts the deployment process targeting the chosen environment so you don't need to modify any code to switch deployment targets.
Its output should be the addresses of the resources that were actually deployed (whether on a public or private network).
This makes it really easy to integrate automatic end-to-end tests into your development pipeline.
Simply have your test runner deploy your app to a test environment, run tests on it, then clean up.
Congratulations, you've just tested a complete version of your app, exactly like your users will see it.

\infobox{More on remote tests}{
  If you have many developers running tests at the same time (or an automated system running your test suite on multiple commits at once), it won't be enough to just have a single test environment.

  It's best to have mutiple completely separate test environments, but this may get expensive if tests are constantly running.

  You may need to scale down the resources for each deployment to save costs, especially if your tests take a long time to run.
  But remember that every change you make will set your test enviroment apart from production so do so sparingly.
}

\subsection{Fusion}

There's a lot to love about CDK in particular, such as the way it handles granting permissions between objects and outputs from infrastructure stacks.
But the documentation is a better place to learn about that.
Here I'll give you one more reason to write your code in a full-fledged programming language.

Your app is likely to contain multiple pieces of cloud infrastructure and those different components will want to talk to each other.
In order to tell your server, for example, where the database lies, you can very easily pass the ID of the database in an environment variable to the server.
You do this by accessing the ID property of your database object and, through the magic of code generation, the synthesizer will ensure that the right values get placed into the constructed template.
This interfacing between hardware isn't just convenient; it is a crucial to establishing a hermetic system as a whole even when there are hundreds of cloud resources because each one knows how to directly connect (often using your cloud provider's private intranet) to each other one if it needs to!

\section{Heavy metal}

Back when applications ran on servers you bought directly from Dell~\cite{joel-dell} and the first hire you needed to set up such a system was a sysadmin, it was difficult to create production-scale software with multiple components that was available to everyone on the internet.
Nevertheless people persevered, until the 2000s when the launch of AWS brought IaaS, and most importantly, virtual servers-for-rent, into the hands of anyone who could figure out how to use it.
AWS's product Elastic Compute Cloud (EC2)~\cite{ec2} offers (to this day) virtual compute instances that can be launched, programmed, and terminated at the click of a button.

Here's how development on EC2 might go.
A programmer wants to build the backend for their app (perhaps it's a music app that needs to fetch the user's song playlist from a database), so they put together a Flask~\cite{flask} scafolding like the following:

\begin{verbatim}
import api
from flask import Flask, request, Response

app = Flask(__name__)

@app.route("/authenticate", methods=["POST"])
def authenticate():
  # Verify the user's credentials and return a session.
  pass

# ...

@app.route("/next", methods=["GET"])
def next():
  # Return the next song in the user's playlist.
  pass

if __name__ == "__main__":
    app.run()
\end{verbatim}

This is a basic HTTP API where each \icode{@app.route} declares an endpoint for the client app to access.
They create a script \texttt{serve.sh} which contains the necessary commands to start the Flask server.
Now the developer needs to run the API service in a way that is (1) accessible over the internet and (2) always available, so they choose an instance type and launch an EC2 instance.
They SSH into their instance, copy their code over, and run the script.
They configure the machine to keep the server running after terminating the remote shell, then they log out.
Every EC2 instance can be assigned a public IP (and DNS name under \texttt{compute.amazonaws.com}) so there's no need to configure any CNAMEs or A records.
The server doesn't appear to be working, but after a while they realize that they need to configure the instance's security settings to allow inbound HTTP over the server's port.
Now everything is set.

Well, there's no plan in place for deploying new versions of the backend, or for recovering the application should the server fail, so if they're smart they'll use IaC to make it really easy to at least redeploy the infrastructure.
As for the code itself, they'll have to find another way to get the code up and running automatically during deployment if they want to have a really tight development and iteration pipeline.

What about scaling in response to load?
If this app goes viral the volume of requests to the backend may bring the system to its knees.
Ideally our developer could launch replicas of this instance, each with their own copy of the Flask server.
Even if this were possible, how can they direct traffic to the least encumbered instance?
Elastic Load Balancing (ELB)~\cite{ELB} is usually the answer.

To use ELB they'll need to set up a target group, an autoscaling group, configure listeners to direct traffic through the load balancer's ports\ldots.

But wait!
This is getting out of hand!

The develop just wanted to expose some functions over the internet.
To do that, they encapsulated the routes in a "server" using Flask, then used EC2 to host the server (though of course little more than the server's intermittent computing power and network connectivity was needed), then set up a whole bunch of infrastructure to replicate the code across servers and direct user requests.

This seems like a lot of trouble for something so ubiquitous as a web API!
Can't we just work with route functions directly?

\section{Function-as-a-Service}

Yes, that's really what it's called:

\begin{quote}
  Function-as-a-Service, or FaaS, is a kind of cloud computing service that allows developers to build, compute, run, and manage application packages as functions without having to maintain their own infrastructure.~\cite{redhat-faas}
\end{quote}

The idea is quite simple; if you can run a function on your own computer, why can't you run it on someone else's computer too?
By "someone else's computer" I mean the cloud, and by "function" I mean some piece of code that executes in response to an event.

Cloud provider \term{FaaS} offerings make it super easy to package up your code and deploy it to a fully managed environment where you pay only for the resources used when your functions are actually running.
FaaS is a form of \term{serverless} computing, and lots of people are wrong about exactly what that means.

\section{Serverless versus stateless}

Contrary to what many authors would have you believe, \term{serverless} and \term{stateless} are not the same.
As defined by Amazon Web Services, serverless~\cite{serverless} consists of three parts:

\begin{enumerate}
    \item automatic scaling
    \item built-in high availability
    \item a pay-for-use billing model
\end{enumerate}

But it's probably best encapsulated by the tagline "build and run applications without thinking about servers."

On the other hand, \term{stateless} is purely a software-architectural pattern.
It refers to applications that handle each invocation instance separately, without persisting any data between executions.
Now stateless is certainly a spectrum.
An application riddled with global variables has more persistant state than one that acts mostly as a pure function with the exception of occasional trips to an external database to save some data.

But FaaS products like AWS Lambda are not really stateless.
Not just because lambdas can read and write external storage, but also because individual invocations are not completely isolated.
Lambdas can keep state both in their local memory and in their temporary filesystem.
Why isn't local memory wiped between invocations?
Because in practice this would lead to too many \term{cold starts}, users waiting a long time because the lambdas they are trying to invoke are booting up.

Another type of serverless computing, serverless compute containers (such as those offerd by AWS Fargate~\cite{fargate}) are clearly not stateless.
Much like with any containerized application, you can keep state however you want; the difference is that Fargate does not make you choose an instance type to run your containers on.

(And of course actual servers are sometimes stateless too\ldots.~\cite{xkcd-1})

\section{What we've learned}

So far we've learned a lot about elegant cloud application design.
We've covered consistency, statelessness, infrastructure as code, FaaS, and serverlessness.

Now it's time to move to the more hands-on parts of the software development lifecycle and apply our methodologies to some examples.

\section{Marcus}

Marcus is an SMS bot, a chat app that the user interacts with by sending and recieving text messages.
There are many use-cases for an SMS bot like this one.
For example:

\begin{enumerate}
  \item Create and manage lists and share them with friends over the internet (shopping lists, reading lists, etc.).
  \item Add an event to your calendar app.
  \item Start playing a song from your library.
  \item Set an alarm.
\end{enumerate}

Anywhere you might use your phone's voice assistant ("add an event/reminder to my calendar today at 6PM") you might wish to do with Marcus instead.
Marcus is faster to use than Siri or Google Assistant and there's no risk of your voice being misunderstood.
I like to think of Marcus as the command line for your phone.

Here's a sample user interaction with Marcus, where user's commands look like \user{this} and Marcus's replies look like \marcus{this} (explanation on the right).

\begin{tabular}{ l | l }
  \user{Lm, groceries} & Make a list called "groceries." The command \user{Lm} means "List make." \\
  \marcus{groceries: created list.} & \\

  \\

  \user{La, groceries, milk, dozen eggs} & Append two items to the "groceries" list. \\
  \marcus{groceries: added 2 lines.} & \\

  \\

  \user{Lp, groceries} & Print the "groceries" list. \\
  \marcus{1: milk} & \\
  \marcus{2: dozen eggs} & \\
  \marcus{\textasciitilde} & \\

  \\

  \user{Lr, groceries, 1, soy milk} & Replace line $1$ in the "groceries" list with "soy milk." \\
  \marcus{groceries: replaced line 1 with soy milk.} & \\

  \\

  \user{Lp, groceries} & Print the "groceries" list. \\
  \marcus{1: soy milk} & \\
  \marcus{2: dozen eggs} & \\
  \marcus{\textasciitilde} & \\
\end{tabular}

Let's design and architect this app.
We start by identifying the mechanism we'll use for receiving and acting on text messages automatically.
Let's use Twilio, a telecommunications API, because it provides the developer with a phone number for the bot and will automatically send an HTTP request to a webhook supplied by the developer whenever the bot receives an SMS.
Whatever we program our webhook to respond with will be sent back from the bot as a text.
Great!

So what do we need to do to create a webhook?
A webhook is just an HTTP endpoint that can respond to events.
In this case, it will get the contents of the text message, execute the user's command, and return the results.

This sounds like a perfect use case for FaaS!
AWS Lambda will suit us well.
Our architecture will thus consist of:

\begin{enumerate}
  \item A lambda to resolve SMS "queries" and return SMS "responses."
  \item An API Gateway to expose the lambda through a public HTTP endpoint. This is not strictly necessary anymore as lambdas now support the assignment of function URLs directly. This feature just came out five days ago! But we'll stick with the old way for the time being.
  \item Whatever else we need to store persistant data.
    For example, to implement the List application from above, we may want an object bucket to store the lists as files.
\end{enumerate}

When you think about it, this is pretty simple.
Compare this approach to one which does not use FaaS.
To launch your desired application logic (a single function which transforms input text messages to output text messages) you would need to launch an entire, say, Flask application on a server, or at the very least put your application inside a container and use a container orchistration service.
It would be much more expensive because you will be paying even when your function is not running, but even more importantly, it would be much more difficult to deploy and test.
This is because the more infrastructure that you manage yourself, the more time it takes to configure your app.
Furthermore, since lambda scales in reponse to load automatically, you don't even need to think about your app throttling.

Now we consider what needs to go into this lambda.
Modulo some error checking and details of the Twilio API, the code boils down to:

\begin{verbatim}
/**
 * Resolve the SMS query.
 * @param event the SMS event containing the message contents.
 */
const lambdaHandler: SmsLambdaHandler = async (event) => {
  const parsedRequestBody = parseRequestBody(event.body);

  if (!isAuthorizedRequest(parsedRequestBody)) {
    return "You are not authorized";
  }

  const userMessage = parsedRequestBody.get("Body");

  // Convert the request SMS into tokens.
  const tokens = lexTokens(parsedRequestBody.get("Body"));

  // Convert the tokens into a command.
  const command = parseCommand(tokens);

  // Run the command and catch any unresolved errors.
  try {
    const commandResult = await command.execute(...command.args);
    return commandResult.message;
  }
  catch (err) {
    return `Uncaught error when running command: ${String(err)}`;
  }
};
\end{verbatim}

where \texttt{lexTokens}, \texttt{parseCommand}, and each command's \texttt{execute} function are defined elsewhere.

As you can see, the code for Marcus isn't very complex, and all commands can be handled by a single lambda handler, so there's really no need to launch a server or run a managed container.
What we want is a function running in the cloud and that's exactly what we get.

As you've guessed by now, we'll encode the infrastructure using IaC.
Let's take a quick look at a portion of the main IaC file for Marcus:

\begin{verbatim}
/* Store data for the List application. */
const listBucket = new s3.Bucket(this, "ListBucket", {
  bucketName: "marcus-list-bucket",
  versioned: true,
  encryption: s3.BucketEncryption.S3_MANAGED,
});

/* Receive SMS messages and send a message back. */
const smsResolverLambda = new nodelambda.NodejsFunction(this, "SmsResolverLambda", {
  functionName: "MarcusSmsResolverLambda",

  runtime: lambda.Runtime.NODEJS_14_X,
  entry: "gateway/resolver.ts",
  handler: "lambdaHandler",
  tracing: lambda.Tracing.ACTIVE,

  timeout: Duration.seconds(3),

  bundling: {
    minify: true,
    banner: "/* Marcus Sms Bot - minified and bundled. */",
  },

  environment: {
    MARCUS_REGION: "us-east-1",
    MARCUS_LIST_BUCKET_NAME: listBucket.bucketName,
    MARCUS_APPROVED_USER_PHONE_NUMBERS: fs.readFileSync(userPhoneNumbersFileName),
  },
});
listBucket.grantReadWrite(smsResolverLambda);

/* Provide access to our SMS resolver lambda. */
const api = new apigateway.RestApi(this, "SmsGatewayApi", {
  restApiName: "MarcusSmsGatewayApi",
  disableExecuteApiEndpoint: false,
});
const receiveSms = api.root.addResource("receiveSms");
receiveSms.addMethod("POST", new apigateway.LambdaIntegration(smsResolverLambda));
\end{verbatim}

First, we create an S3 bucket to store the lists for the List program.
By storing on the cloud, multiple users of Marcus can interact with the same lists.
Of course, we can add access controls if we don't want lists to always be public.

Second, we create the TypeScript lambda to resolve the SMS queries.
Notice how we pass environment variables into the lambda function.
This is how we "connect" the lambda to the S3 bucket and tell the lambda who is approved to use Marcus.
Since \texttt{userPhoneNumbersFileName} refers to a text file in the repository, the data we are injecting here is completely controlled by the version control commit.

Third, we expose our Lambda to the internet through an API Gateway whose single HTTP POST endpoint "/receiveSms" will be given to Twilio as the webhook.

Now the List program can use the TypeScript AWS SDK to connect to S3 and upload a list like so:

\begin{verbatim}
const s3Client = new S3({
  region: process.env.MARCUS_REGION,
});

await s3Client.putObject({
  Bucket: process.env.MARCUS_LIST_BUCKET_NAME,
  Key: listName,
  Body: listText,
});
\end{verbatim}

Note how we use Node's \texttt{process.env} to access the environment variables we passed earlier in the IaC.

I can't stress enough how easy it is to develop and deploy this application.
All three major pieces of infrastructure we've used do not require us to provision hardware or choose an instance type, and there is no state aside from the lists stored in the bucket.
CDK is smart.
If the bucket's configuration doesn't change, it will simply remain during a new deploy.
If it does change, CDK will create a new bucket, detatch the old one from our stack, and preserve its data.

\subsection{Results}

Marcus is a real app that I wrote for this report and the code can be found here~\cite{marcus}.
The most expensive part of its operation is its usage of Twilio.
With only a few users, the entire AWS side of things is nearly free.

I use Marcus all the time to create lists because it is extremely fast and convenient and I encourage anybody who is interested in learning how to write cloud software to fork the project and start writing Marcus commands of their own.

\screenshot{marcus-infra}{Infrastructure diagram for Marcus.}

\section{Traxler}

A small note on interfaces.
The Marcus project interfaces with the user through SMS.
This means that you can talk to Marcus through the messages app on your phone.

Many cloud applications are web apps which interface with the user through their browser.
To make an app for the browser, there are two main paths.

The first is to have a server generate HTML files upon request and return them to the user.
This is called server side rendering (SSR) and should be familiar from the days of PHP.
Below we'll discuss Jongleur which uses this approach.

The second is to host static files that are served as-is to the user.
Those files can have JavaScript in them that pull down dynamic data at runtime, but this is different from SSR which injects the data into the page before the client sees it.
Static files can be served from a CDN at the speed of sound.

This development practice is often called Jamstack~\cite{jamstack} by believers.
The limitations of throwing away your server are made up for by a simpler hosting strategy.
As long as you make uploading your static content part of your deployment pipeline, you'll have an easy time developing and updating your app.
It also makes it easy to launch a hermetic version of your app that you can run tests against.
This is the approach used by Traxler~\cite{traxler}, a defunct directory for Princeton students that I wrote two years ago.

\index{Continuous delivery}
\infobox{Continuous delivery}{
  Why all the focus on easy deployments and Hermetic Servers?
  
  When your application can be thoroughly tested in a consistent manner, you enable short development loops and Continuous Delivery (CD).
  CD is the practice of giving your app's users regular cuts from your main branch without having to worry about things breaking.

  To make this possible, merged commits should trigger a full build and a suite of automated tests.
  If the tests pass, you should have the ability to tell the system to run a full deployment without manual intervention.
}

\section{Jongleur}
\label{JONG}

Now I present the main object of study in this report: Jongleur.

Jongleur is the musician's assistant; users can upload practice recordings of sessions spent at their instrument and Jongleur will catalogue the audio, tracking how long the user has practiced a piece and storing and splitting the practice waveform into logical segments for playback.

\screenshot{jong-practice}{A user's practice recording is displayed along with a timeline of all other practice sessions of this piece. Clicking on any colored part of the waveform will play that segment of the original audio file.}

\subsection{Those who have come before us}

To understand our app's domain better, it's useful to consider related apps that already exist.

The practice app Instrumentive~\cite{instrumentive} for mobile devices records the practicing musician and tracks practice time.
It doesn't sort recordings by the piece the user was practicing or split the audio into segments but it provides a nice interface for tracking practice hours and setting goals.
It even comes with an included metronome.

For those learning with an instructor, Better Practice~\cite{better-practice} lets the student share their practice log with their teacher.

Apps like Simply Piano~\cite{simply-piano} help the student learn their instrument in a lesson-based style; on the other hand, Jongleur does not distract the user while they are playingbut instead waits for them to upload an audio file at the end of their session.

\subsection{Overview}
Jongleur is a full-stack web app built on AWS in several thousand lines of code.
The majority is Typescript, but some Python is used for audio analysis.
The app consists of quite a lot of infrastructure.

The architecture of the app follows the design patterns we've developed.
Great care went into the quality of its code; it's well organized, doesn't make "tech-debt" compromises in many places, and is extremely extensible and easy to build off of.
Where security is important, I've made it a focus.

On the frontend, I'm using Remix,~\cite{remix} a new React framework (it went open source just this past Thanksgiving).
Its focus is on nested routing and server-side generation of pages.

The backend consists of four main components:

\begin{enumerate}
  \item Authentication / authorization
  \item Data
  \item Audio
  \item GraphQL
\end{enumerate}

How would we scope out and design this app?

\subsection{Features}
textit
First, consider the features we want to support.

\subsubsection{User accounts}

Because musicians should be able to track their own statistics and view only their own practice recordings, we must allow the creation of user accounts.
This means we need to support signing up and signing in.
Our frontend must be able to pull customized data about the current user and display it on the web page.

\screenshot{jong-signup}{A user can enter a username and password to create an account and join the party.}

\subsubsection{Practice pieces}

The app should show a list of pieces that a user can practice.
Selecting a piece should show the user all of the practice sessions they've already had for that piece on a timeline.
Selecting a session should show the practice recording's waveform along with some information such as the tempo of the recording.

\subsubsection{Audio playback}

Practice waveforms should be sliced into segments separated by periods of silence (where the musician paused to try replaying a section of the piece).
Each segment should display in a different color and clicking on a segment should play that part of the original audio file.

\subsubsection{Your stats}

Each user should be able to see an overview of the pieces they've practiced and they should be able to click on each one to view a list of all the practice recordings they've uploaded.
The user should also have access to aggregated stats about their total practice time.

\screenshot{jong-stats}{On their stats page, a user sees a list of their favorite pieces to practice and the total amount of practice that they've completed.}

\subsection{Architecture}

Now that we understand what the app should do, let's figure out how to make it happen.
Some of the features above will translate into a lot of infrastructure.
But because we are using AWS CDK, we'll be able to manage it all quite nicely.\footnote{https://github.com/josephrubin/jongleur/blob/master/infrastructure/lib/jongleur-infrastructure-stack.ts}

\subsubsection{Auth}

AWS's serverless identity management offering is Cognito; its abundant configuration options makes it somewhat difficult to understand but it makes up for this by being extremely useful.
We'll use a Cognito user pool configured to allow admin actions (such as creating and verifying users) only from our backend.

Cognito allows the developer to store most user data in the user pool but we'll store it with the rest of our data to make it easier for us to pull it all down together to the frontend.

When a user signs in, we'll have Cognito generate an access token (in the form of a JSON Web Token) that they'll use to make authenticated requests.
They'll also get a refresh token which allows the user to request a new access token when theirs expires.

When the frontend makes an API request on behalf of the logged in user, our backend will verify and decode the JWT to figure out what actions the user should be able to take.

\subsubsection{Data}

Let's create a data model.
The main objects that our app deals with are the Piece and the Practice.
Pieces will represent music that a user can practice.
When a user uploads an audio recording, we'll create a Practice and file it under the Piece that they've selected.

\begin{figure}[h]
  \centering
  \tikzstyle{single} = [rectangle, rounded corners, minimum width=2.427cm, minimum height=1.5cm, text centered, draw=black]
  \tikzstyle{arrow} = [thick,->,>=stealth]
  \tikzstyle{doublearrow} = [thick,<->,>=stealth]
  \begin{tikzpicture}[node distance=4cm]
    \node (one) [single] {Piece};
    \node (two) [single, right of=one] {User};
    \node (three) [single, below of=one] {Practice};
    \node (four) [single, right of=three] {Session};
    \node (five) [single, below of=three] {Segment};
    \node (six) [single, right of=five] {Audio File};

    \draw [doublearrow] (one) -- (three);
    \draw [doublearrow] (two) -- (three);
    \draw [doublearrow] (three) -- (five);
    \draw [arrow] (two) -- (four);
    \draw [arrow] (five) -- (six);
  \end{tikzpicture}
  \label{fig:sdl}
\end{figure}

Each Practice will store some metadata and a scaled-down version of the original waveform to be displayed on the frontend as a series of amplitudes.
A Practice will be made up of a number of Segments, calculated in advance during the audio processing pipeline.
Segments will contain their portion of the waveform and a link to a presliced audio sample from the original recording.

All the data that we want to store in our backend needs to go into a database of some sort.
We could go with a classical relational database, but this will be overkill as we won't be doing any complicated JOINs when we query data.
Fitting our data into a serverless key-value store like DynamoDB will pay off dividends in the future because DynamoDB is faster to deploy, automatically scales, and doesn't require us to execute SQL commands to create a schema.

To support the database queries that we'll need, we'll create a few DynamoDB global secondary indices.
At this point in the planning, though, we don't know yet what queries will be most useful.
This is where IaC really shines; when we know more, it's easy to come back to our infrastructure files and make modifications.

There's one more thing: since our app needs to hold on to the audio files uploaded by users, we'll have an S3 bucket available for this purpose.
Actually, we'll have two buckets.
One for the files the user uploads, and one for the slices that our audio processing pipeline emits.
The S3 bucket with the final audio files will sit behind a CloudFront distribution to serve these large files quickly.

Because we are using JWTs, a login session from the perspective of Cognito will be stored as a cookie on the user's browser so we don't need to reserve a place for it in our infrastructure.

\subsubsection{GraphQL}

This whole time we've been talking about the backend without concretely designing its function.
Recall our data model; it's a bunch of objects sitting in a relational graph.

Thus it is sensible to use GraphQL to expose our queries and mutations.
GraphQL makes us define a resolver, basically a piece of code that connects the API to the data store.
This is a great time to use our old friend, AWS Lambda.

Our lambda will take as input the object and field that we're trying to resolve and, respecting the current user session, retrieve from or update the database.
Thus this resolver will contain the majority of our backend code.

When a user signs up or signs in, it is the resolver that will invoke Cognito to take the appropriate action.

Our resolver knows where all the data is kept because we wire this information through environment variables in our IaC.

AWS offers a serverless implementation of GraphQL called AppSync; this will work for our purposes.
To tell AppSync about the API surface we want to support, we will write a GraphQL schema\footnote{https://github.com/josephrubin/jongleur/blob/master/graphql/schema.graphql}.
Using a tool called \texttt{graphql-codegen} we'll generate TypeScript interfaces for all the types in our schema whenever we edit the file.
This will help immensely when it comes to programming the frontend, because our React code will know exactly what fields to expect from the backend.

This will also help in programming the backend resolver, because it is also written in TypeScript and as such will be able to know exactly what fields to expect from the data stores.

\subsubsection{Audio}

The other part to our backend is the audio processing pipeline which is also built from AWS Lambda.
Here, every decision we make must keep in mind that audio files can be quite large, especially as we expect our users to upload practice recordings that are a few hours long.
Because of this, we can't assume that our lambdas will be able to fit the entire file in memory at once.

\isubsubsubsection{Uploading audio}

The pipeline will begin when the user uploads an audio file.
Here's the first challenge.
Almost all of our client-server interaction happens through our GraphQL API, but it would be wasteful to try and stream large audio files through any excess middleware.
We want the user to be able to upload a file directly to an audio intake S3 bucket, using the browser's native capabilities for multi-part background uploads.

The thing is, we don't want to expose our S3 bucket to the public and allow anyone to upload files, so the upload process will actually consist of two steps.

First, the user requests a \term{presigned url} from the backend, which is an upload target to a specific spot in S3 that is associated with their account.
Then, using this URL (before it expires), the user can make the upload directly to the bucket.

One of the hallmarks of serverless design is the \term{event}.
When an upload completes, S3 will generate an event to kick off the audio processing.

\isubsubsubsection{Processing audio}

We'll do audio analysis on the backend using the Python library librosa.~\cite{librosa}
We want to do this in a lambda, but this might take a while, so we want to let the user know something is happening.

Let's pull another serverless tool out of our belt, the AWS Step Function.
A Step Function can run a sequence of tasks in series, gracefully catching errors and retrying or recovering.
Our state machine will consist of three parts:

First, record in DynamoDB that we are processing a new audio file.
Second, do the actual processing.\footnote{https://github.com/josephrubin/jongleur/blob/master/audio/process/main.py}
Third, record that we are done (either succeefully or with an error).

The actual processing will be done on the audio file in chunks because we can't load the entire thing at once.
We'll pull the entire file down from S3 into the lambda's temporary file system and then read it one block at a time using librosa's streaming capabilities.

The main thing we want to do is identify nonsilent intervals of music.
Each block can be easily split on its own, but we'll have to implement a custom algorithm to merge the results of adjacent blocks.
We won't go into depth on this here because that's not the point of this paper, but feel free to take a look at the code.

Now that we have a list of pairs of frame indices representing intervals, we'll need to split the audio file and upload each chunk to an S3 bucket.
Because each interval could ostensibly be as long as the entire audio file (if there is no silence at all), we have to assemble each audio chunk in blocks.
Librosa can't do this, but luckily, we can use ffmpeg.

As mentioned previously, our destination S3 bucket will be hooked up to CloudFront so our backend can return authenticated URLs to user audio content that streams to the user's device extremely quickly.

\subsubsection{Web}

The Remix web app contains frontend TypeScript and data loaders which technically run on the server and make requests to our GraphQL API.
It's not super easy to pull out all of the server-side code and make lambdas out of them while hosting the frontend statically.
Instead, we'll package the whole Remix app into a Docker image and run it on AWS Fargate, Amazon's serverless container engine.

Because Fargate expects a container definition in order to deploy our app's tasks, uploading the code is just another part of the deployment pipeline.
This is a big win for us because it means that no additional work needs to be done to start our app after the containers launch.

\subsection{Implementation details}

Now that we know how all the pieces fit together it's time to write the code!
But architecting everything was the hard part; since we know which modules need access to what, we should be able to complete each part in isolation.
I find that it's best to start with the the GraphQL schema, then the IaC, ensuring that you pass the appropriate environment variables around the stack, then develop the frontend and backend in tandum.

One thing that will make development easier is setting up scripts for common tasks.
There's never any reaseon to waste time chaining together a series of commands when you can make a single script to run all of them.
For example, I have a script that runs the Remix app locally for development, but first that same script also runs type generation on the graphql schema to keep everything in sync.

\subsubsection{Challenges}

A few challenges came up as I was completing the project.
One of them was that the Python audio and data libraries were so large that they couldn't fit in a standard lambda so I had to create a Docker image that runs the lambda service and make a container lambda out of it which is allowed to be larger.

Another challenge was that S3 events can't actually trigger Step Functions directly but rather only lambdas so I had to create a small lambda to bridge the gap.

At the end of the day we have a fully fledged app that tailors itself to the user.

\screenshot{jong-home-in}{The homepage when a user is logged in.}

\subsubsection{Results}

The result of the implementation is a project that is about 80\% TypeScript, 10\% Python, 10\% assorted utility languages; contains about 900 source lines of infrastructure code that synthesizes to over 3000 lines of CloudFormation and over 100 cloud resources; and contains over 6000 source lines of code total.

The app can handle audio files of any size that I've thrown at it, and it does so relatively quickly.

There are some things lacking, though.
For one, users are not able to add their own pieces to the platform; they must choose a piece that is already there under which to file their recording.

For another, while GraphQL's ability to define structured queries that the client can use to retreive precisely the desired data is incredibly useful, it is not a free lunch.
It is well known that GraphQL APIs can suffer from server-side overfetching and indeed Jongleur can be slow at times.
I implemented some data caching to speed up the app, but caching in general is a hard problem in computer science and I felt that my time was better spent developing the architecture to make a clean demonstration of software design for this report.

The best part about Jongleur is that the infrastructure is all serverless.
There are no bare EC2 instances or ECS containers running Jongleur code.
That means we'll never have to worry about individual machines going down and we will be paying as little as possible when our application isn't being heavily used.

All of the infrastructure is written as code in CDK which makes it reproducible and also easy to deploy.
You can launch the full stack with one command.~\cite{jongleur}

\screenshot{jong-infra}{Infrastructure diagram for Jongleur. In the interest of clarity, I've included only the most important components of each layer and have abstractly represented the inter-layer dependancies.}

\subsection{Conclusions and a thought toward the future}

The design opinions I've expressed in this paper aren't just theoretical.
These guidelines that I've researched and written about are in use in the projects I've discussed above as well in the Full Measure Education Campus Visit Experience~\cite{cve}, a project that I co-founded that is currently in use by visitors to over $60$ universities across the country.

The issue with writing software without regard for proper design is that your project will not outlast you.
Do your future collaborators a favor and allow them to build off your work, not replace it.

\section{Acknowledgements}

A genuine appreciation for Dr. JÃ©rÃ©mie Lumbroso for advising this project.

\section*{Statement of Academic Integrity}

This thesis represents my own work in accordance with University regulations.\\
Signed, /Joseph Rubin/.

%\bstctlcite{bstctl:etal, bstctl:nodash, bstctl:simpurl}
%\bibliographystyle{IEEEtranS}

% References.

\bibliographystyle{plain}
\bibliography{references}

% Index of terms.
\printindex

\section{Appendix}

TODO: any additional screenshots.
jong and marcus and traxler.

\end{document}

